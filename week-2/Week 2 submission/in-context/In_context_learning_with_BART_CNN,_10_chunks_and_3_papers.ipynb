{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT17_Ti4-kjA",
        "outputId": "bf34660d-da35-4c4b-e4fb-db308efb35ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/298.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying with 10 chunks and 3 papers"
      ],
      "metadata": {
        "id": "MWcWGWzW-nNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It run for 9 min"
      ],
      "metadata": {
        "id": "sjHnIg6yFshZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, urlretrieve\n",
        "from IPython.display import Markdown, display\n",
        "from pypdf import PdfReader\n",
        "from datetime import date\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configuration variables\n",
        "MAX_PAPERS = 3\n",
        "MAX_CHUNKS = 10\n",
        "\n",
        "# Initialize BART-CNN summarizer with specific parameters\n",
        "summarizer = pipeline(\"summarization\",\n",
        "                     model=\"facebook/bart-large-cnn\",\n",
        "                     device=0)  # Use GPU if available\n",
        "\n",
        "# HuggingFace papers scraping\n",
        "BASE_URL = \"https://huggingface.co/papers\"\n",
        "page = requests.get(BASE_URL)\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "h3s = soup.find_all(\"h3\")\n",
        "papers = []\n",
        "for h3 in h3s[:MAX_PAPERS]:  # Only process MAX_PAPERS\n",
        "    a = h3.find(\"a\")\n",
        "    title = a.text\n",
        "    link = a[\"href\"].replace('/papers', '')\n",
        "    papers.append({\"title\": title, \"url\": f\"https://arxiv.org/pdf{link}\"})\n",
        "print(\"printing papers:\", papers)\n",
        "def extract_pdf(url):\n",
        "    pdf = urlretrieve(url, \"pdf_file.pdf\")\n",
        "    reader = PdfReader(\"pdf_file.pdf\")\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "def chunk_text(text, max_chunk_length=1024):\n",
        "    \"\"\"Split text into chunks that BART can process\"\"\"\n",
        "    sentences = text.split('.')\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip() + '.'\n",
        "        if current_length + len(sentence) <= max_chunk_length:\n",
        "            current_chunk.append(sentence)\n",
        "            current_length += len(sentence)\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [sentence]\n",
        "            current_length = len(sentence)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_text(text, max_summary_length=150):\n",
        "    \"\"\"Summarize text using BART-CNN with optimized chunking\"\"\"\n",
        "    # Clean and prepare text\n",
        "    text = ' '.join(text.split())  # Remove excessive whitespace\n",
        "\n",
        "    # Only process first 5000 words to avoid excessive processing\n",
        "    text = ' '.join(text.split()[:5000])\n",
        "\n",
        "    # Split into smaller chunks\n",
        "    chunks = chunk_text(text, max_chunk_length=1024)\n",
        "\n",
        "    # Process only specified number of chunks\n",
        "    chunks = chunks[:MAX_CHUNKS]\n",
        "    print(f\"Processing {len(chunks)} chunks...\")\n",
        "\n",
        "    summaries = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        try:\n",
        "            print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
        "            summary = summarizer(chunk,\n",
        "                               max_length=max_summary_length,\n",
        "                               min_length=30,\n",
        "                               do_sample=False,\n",
        "                               truncation=True)\n",
        "            summaries.append(summary[0]['summary_text'])\n",
        "        except Exception as e:\n",
        "            print(f\"Chunk summarization failed: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Combine and summarize again if needed (takes time)\n",
        "    final_summary = ' '.join(summaries)\n",
        "    if len(final_summary.split()) > max_summary_length:\n",
        "        try:\n",
        "            final_summary = summarizer(final_summary,\n",
        "                                     max_length=max_summary_length,\n",
        "                                     min_length=30,\n",
        "                                     do_sample=False)[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            print(f\"Final summarization failed: {e}\")\n",
        "\n",
        "    return final_summary\n",
        "\n",
        "# Process papers with progress bar\n",
        "for paper in tqdm(papers):\n",
        "    try:\n",
        "        print(f\"\\nProcessing: {paper['title']}\")\n",
        "        text = extract_pdf(paper['url'])\n",
        "        print(f\"Text extracted, length: {len(text.split())} words\")\n",
        "        paper[\"summary\"] = summarize_text(text)\n",
        "        print(f\"Summary generated, length: {len(paper['summary'].split())} words\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing paper: {e}\")\n",
        "        paper[\"summary\"] = \"Processing failed\"\n",
        "\n",
        "# Generate markdown output\n",
        "output = \"# Paper Summaries\\n\\n\"\n",
        "for paper in papers:\n",
        "    # Make sure we have both 'title' and 'summary' keys\n",
        "    title = paper.get('title', 'No Title')\n",
        "    summary = paper.get('summary', 'No Summary')\n",
        "    output += f\"## {title}\\n\\n{summary}\\n\\n---\\n\\n\"\n",
        "\n",
        "printmd(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Cx0q4t2AI_1",
        "outputId": "4035a179-a4da-4d4d-bb21-6e60fe475500"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'title': '2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining', 'url': 'https://arxiv.org/pdf/2501.00958'}, {'title': 'VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control', 'url': 'https://arxiv.org/pdf/2501.01427'}, {'title': 'CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings', 'url': 'https://arxiv.org/pdf/2501.01257'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: 2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted, length: 12256 words\n",
            "Processing 10 chunks...\n",
            "Processing chunk 1/10\n",
            "Processing chunk 2/10\n",
            "Processing chunk 3/10\n",
            "Processing chunk 4/10\n",
            "Processing chunk 5/10\n",
            "Processing chunk 6/10\n",
            "Processing chunk 7/10\n",
            "Processing chunk 8/10\n",
            "Processing chunk 9/10\n",
            "Processing chunk 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [03:20<06:41, 200.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary generated, length: 46 words\n",
            "\n",
            "Processing: VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control\n",
            "Text extracted, length: 6432 words\n",
            "Processing 10 chunks...\n",
            "Processing chunk 1/10\n",
            "Processing chunk 2/10\n",
            "Processing chunk 3/10\n",
            "Processing chunk 4/10\n",
            "Processing chunk 5/10\n",
            "Processing chunk 6/10\n",
            "Processing chunk 7/10\n",
            "Processing chunk 8/10\n",
            "Processing chunk 9/10\n",
            "Processing chunk 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [06:08<03:01, 181.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary generated, length: 40 words\n",
            "\n",
            "Processing: CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings\n",
            "Text extracted, length: 8689 words\n",
            "Processing 10 chunks...\n",
            "Processing chunk 1/10\n",
            "Processing chunk 2/10\n",
            "Processing chunk 3/10\n",
            "Processing chunk 4/10\n",
            "Processing chunk 5/10\n",
            "Processing chunk 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 136. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing chunk 7/10\n",
            "Processing chunk 8/10\n",
            "Processing chunk 9/10\n",
            "Processing chunk 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [09:14<00:00, 184.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary generated, length: 32 words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Paper Summaries\n\n## 2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining\n\nInterleaved corpora enable Vision-Language Models (VLMs) to understand the world more naturally like humans. Such exist- ing datasets are crawled from webpage, facing challenges like low knowledge density and loose image-text relations. Our textbook collects over 2. 5 years of instructional videos, totaling 22,000 class hours.\n\n---\n\n## VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control\n\nVideoAnydoor is a zero-shot video object insertion frame- work. It warps the pixel details according to the trajectories and fuses the warped features with the diffusion U-Net. Users could further add multiple objects or swap objects in the same video.\n\n---\n\n## CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings\n\nCodeElo is a benchmarking tool for large language models (LLMs) o1-mini and QwQ-32B-Preview stand out significantly, achieving Elo ratings of 1578 and 1261, respectively. Other models struggle even with the easiest problems.\n\n---\n\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}